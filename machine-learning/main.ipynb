{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Começaremos estudando machine learning através das árvores de decisão. São simples de entender e são também a base de outros modelos preditivos mais avançados. Vamos utilizar as árvores de decisão para nos ajudar a prever preços de casa.\n",
    "\n",
    "O modelo aprende alguns padrões a partir de dados históricos e nos ajuda a fazer a previsão. Essa etapa onde o modelo aprende os padrões é chamado de *fitting* ou *training*, pois estamos de fato treinando o modelo para que aprenda sobre os dados. Os dados utilizados para isso são chamados de *training data*.\n",
    "\n",
    "Primeiramente nossa árvore de decisão vai ter um caminho bem simples, ela divide as casas em apenas duas categorias. Se a casa tem mais ou menos que 2 quartos. Veja imagem abaixo:\n",
    "\n",
    "![image](tree0.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Melhorando nossa árvore de decisão, agora ela considera mais variáveis e ficou um pouco mais complexa. Ela agora pesa mais fatores antes de decidir qual o valor de uma casa. Além da quantidade de quartos, ela considera também o tamanho da casa. Essa que tem mais divisões chamamos de árvores mais profundas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](tree2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos prever o valor da casa percorrendo o caminho da árvore correspondente às características da casa. O ponto onde é feita a previsão é chamado de folha.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instruções sobre estatística básica e primeiras linhas de código com pandas. O curso dá uma visão básica de como é importante fazer um EDA para conhecer os dados. E já mostra a função ```df.describe()```. Fala um pouco de que são média, mediana e percentis, ajudando a interpretar o dataset dos preços das casas.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your First Machine Learning Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui ensina como selecionar colunas com o pandas. Tem a notação com ponto e tem a seleção através dos nomes das colunas dentro dos colchetes. Os nomes das colunas são chamadas de features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para um modelo de machine learning supervisionado precisamos separar a coluna de target, que é o que queremos prever, e as colunas de features, que são os preditores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abaixo por exemplo estaríamos atribuindo a variável y o nosso target do dataset de casas:\n",
    "\n",
    "```y = df_house['price']```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E aqui as features:\n",
    "\n",
    "```features = ['rooms', 'bathrooms', 'landsize', 'lat', 'long']```\n",
    "\n",
    "Por convenção chamamos esses dados de X:\n",
    "\n",
    "```X = df_house[features]```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building Your Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usaremos o scikit-learn para criar nossos modelos. As etapas para a criação de um modelo são:\n",
    "\n",
    "- Definir: qual modelo utilizar..será uma árvore de decisão, outro tipo...\n",
    "- Fit: capture os padrões dos dados históricos\n",
    "- Predict: tente fazer previsões usando novos dados\n",
    "- Avaliar: determinar o quão preciso nosso modelo está performando\n",
    "\n",
    "---\n",
    "\n",
    "Aqui um exemplo de como usar o scikit-learn para criar uma árvore de decisão."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Define model. Specify a number for random_state to ensure same results each run\n",
    "melbourne_model = DecisionTreeRegressor(random_state=1)\n",
    "\n",
    "# Fit model\n",
    "melbourne_model.fit(X, y)\n",
    "```\n",
    "\n",
    "Primeiro instanciamos o modelo e atribuímos um random state. Depois fornecemos os valores X e y a esse modelo instanciado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E para fazer as previsões basta fazer o seguinte:\n",
    "\n",
    "```python\n",
    "\n",
    "melbourne_model.predict(df)\n",
    "\n",
    "```\n",
    "\n",
    "Este df fornecido para o modelo prever são dados novos, mas com as mesmas features (colunas) dos dados de treinamento.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Validation\n",
    "\n",
    "Ok, construimos nosso modelo. Mas, será que ele é bom, como podemos avaliar isso.\n",
    "\n",
    "Essa é uma etapa importante no ciclo de um projeto de data science.\n",
    "\n",
    "Medimos a qualidade do nosso modelo através da precisão da previsão. Ou seja, o quão longe nossa previsão ficou do valor real? A métrica usada para isso é o MAE (mean absolute error), que é a média dos erros absolutos. Basicamente vemos a diferença para mais ou para menos de todas as casas e tiramos a média dessas diferenças. Precisamos dos valores absolutos para retirarmos o sinal de negativo e assim podermos calcular a média. A pergunta que essa métrica nos ajuda a responder é: \"em média, quanto meu modelo está errando?\"\n",
    "\n",
    "Veja no exemplo abaixo como fica isso no código:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "predicted_home_prices = melbourne_model.predict(df)\n",
    "\n",
    "mean_absolute_error(y, predicted_home_prices)\n",
    "\n",
    "# output: 434.71594577146544\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> Veja que o resultado é $ 434.71, ou seja, seu modelo está errando a previsão em relação ao valor real em menos de 500 dólares. É uma ótima previsão em se tratando de valores de casas e apartamentos. Mas saiba que essa precisão toda pode não ser muito boa, como veremos a seguir..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Problem with In-Sample Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perceba que utilizamos o mesmo conjunto de dados para treinar e avaliar o modelo. Isso não é boa coisa e já explico o porquê. Imagine que por algum motivo no seu conjunto de dados todas as casas com porta azul tinham os preços mais caros. Seu modelo vai aprender esse padrão. E quando vc tentar fazer previsões com novos conjuntos de dados ele vai acabar ficando enviesado, estimando erroneamente para mais o valor de todas casas com porta azul. Daí acontece que, se vc testá-lo usando o mesmo conjunto de treino então os resultados sairão ótimos já que o modelo já viu esse dado antes. Porém não veremos o mesmo desempenho na precisão quando trata-se de dados novos. Ou seja, não queremos que o modelo aprenda demais sobre os dados de treino, é importante que ele generalize.\n",
    "\n",
    "A solução para isso é utilizar um mesmo conjunto de dados para treino e para teste. Ao criar o modelo, separamos uma parte dos dados para treino e outra para validação, assim podemos testar o modelo com dados reais e que ele não viu antes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O scikit-learn tem um método para nos ajudar nessa divisão do dataset, é o método ```train_test_split```. Agora faremos essa separação no conjunto de dados e depois vamos novamente fazer o teste MAE para ver como o modelo se comporta. Vamos ver como fica no código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "\n",
    "# criando variáveis fake só para dar o exemplo\n",
    "X = 'features'\n",
    "y = 'target'\n",
    "\n",
    "# dividimos o dataset em treino e teste\n",
    "# isso para ambos features e target\n",
    "train_X, test_x, train_y, test_y = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# agora definimos o modelo\n",
    "melbourne_model = DecisionTreeRegressor()\n",
    "\n",
    "# treinamos o modelo\n",
    "melbourne_model.fit(train_X, train_y)\n",
    "\n",
    "# agora vamos fazer umas previsões \n",
    "# e vamos fazer o teste de precisão\n",
    "predicitions = melbourne_model.predict(test_x)\n",
    "\n",
    "# testando com o método MAE\n",
    "print(mean_absolute_error(test_y, predicitions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">>output: 265806.91478373145"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui vimos como é importante separar o dataset em treino e teste com a ajuda do scikit-learn.\n",
    "\n",
    "Para a maioria dos modelos esse passo a passo será o mesmo. Ou seja, separamos os dados em features e target, depois fazemos o split, instanciamos o modelo, treinamos esse modelo com o split de treino, fazemos as previsões com o split de x_test e depois validamos com o y_test.\n",
    "\n",
    "Veja que agora a precisão ficou bem pior, de apenas $ 434 para $ 265.000! Perceba o perigo de confiar no modelo anterior, treinado e testado com o mesmo conjunto de dados.\n",
    "\n",
    "Mas não se preocupe, existem várias maneiras de melhorarmos este modelo, tais como encontrar melhores features e/ou outros modelos. Veremos mais ao longo do curso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Underfitting and Overfitting\n",
    "\n",
    "- Underfitting: quando o modelo falha em capturar padrões nos dados, levando a previsões menos precisas.\n",
    "\n",
    "- Overfitting: quando o modelo aprende demais sobre os dados. Ele captura padrões muito específicos daquele dataset somente (lembre do caso das cores das portas). Dessa forma, ele também resulta em previsões menos precisas com novos datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No caso das árvores de decisão mais profundas, quando existem mais folhas, os dados vão sendo divididos até chegar a decisão final. Com menos dados para tomar a decisão a previsão fica menos precisa. Funciona bem com os dados de treino, pois as características da casa sempre vão estar lá na árvore. Mas funciona mal com novos dados. Estes são casos de **overfitting**.\n",
    "\n",
    "Já quando a árvore tem menos folhas, o modelo não divide bem os dados em características distintas. Menos divisões, então muito mais dados. Quando o modelo falha em capturar diferenças significativas e padrões nos dados então temos caso de **underfitting**.\n",
    "\n",
    "Nós queremos encontrar um meio termo, nem modelo treinado demais, nem de menos.\n",
    "\n",
    "Para procurar esse meio termo vamos testar profundidades diferentes para cada modelo. E no final vamos eleger o de melhor performance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# criando uma função para depois fazer a iteração\n",
    "def get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y):\n",
    "    model = DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes, random_state=0)\n",
    "    model.fit(train_X, train_y)\n",
    "    preds_val = model.predict(val_X)\n",
    "    mae = mean_absolute_error(val_y, preds_val)\n",
    "    return(mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "    \n",
    "# carregando os dados\n",
    "melbourne_file_path = '../input/melbourne-housing-snapshot/melb_data.csv'\n",
    "melbourne_data = pd.read_csv(melbourne_file_path) \n",
    "# Filter rows with missing values\n",
    "filtered_melbourne_data = melbourne_data.dropna(axis=0)\n",
    "# atribuindo o target e as features\n",
    "y = filtered_melbourne_data.Price\n",
    "melbourne_features = ['Rooms', 'Bathroom', 'Landsize', 'BuildingArea', \n",
    "                        'YearBuilt', 'Lattitude', 'Longtitude']\n",
    "X = filtered_melbourne_data[melbourne_features]\n",
    "\n",
    "# fazendo o split em treino e teste\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y,random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agora vamos comparar o valor de MAE para diferentes\n",
    "# níveis de profundidade\n",
    "for max_leaf_nodes in [5, 50, 500, 5000]:\n",
    "    my_mae = get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y)\n",
    "    print(\"Max leaf nodes: %d  \\t\\t Mean Absolute Error:  %d\" %(max_leaf_nodes, my_mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "output:\n",
    "\n",
    "Max leaf nodes: 5  \t\t     Mean Absolute Error:  347380\\\n",
    "Max leaf nodes: 50  \t\t Mean Absolute Error:  258171\\\n",
    "Max leaf nodes: 500  \t\t Mean Absolute Error:  243495\\\n",
    "Max leaf nodes: 5000  \t\t Mean Absolute Error:  254983"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com esse resultado vemos que a melhor opção é de 500 nós (folhas).\n",
    "\n",
    "Agora que já fizemos as validações, encontramos os melhores parametros e já tomamos as decisões de modelagem, podemos dispensar a fase de validação e treinar o modelo com todos os dados disponíveis, assim melhoramos a precisão. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vamos instanciar o modelo novamente com o parametro ideal encontrado\n",
    "final_model = DecisionTreeRegressor(max_leaf_nodes=500, random_state=0)\n",
    "\n",
    "# usaremos agora todo o dataset para treinar o modelo\n",
    "final_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veja que conseguimos melhorar nosso modelo, mas ainda estamos usando árvores de decisão simples, que não são modelos tão sofisticados. Vamos estudar agora um modelo derivado das árvores de decisão, mas muito mais poderoso.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forests\n",
    "\n",
    "Florestas Aleatórias (Random Forests) são mais poderosas pois são várias árvores de decisão para chegar a uma previsão. Ou seja, ele tira uma média das previsões de todas as árvores de decisão. Dessa forma, esse modelo tem uma precisão preditiva muito maior que uma simples árvore de decisão, além de funcionar muito bem com os parametros default.\n",
    "\n",
    "A diferença no código é bem básica, na etapa de instanciar o modelo, basta instanciar o ```RandomForestRegressor```. O modo de fazer o fit e predições continuam os mesmos. Veja abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "forest_model = RandomForestRegressor(random_state=1)\n",
    "forest_model.fit(train_X, train_y)\n",
    "melb_preds = forest_model.predict(val_X)\n",
    "print(mean_absolute_error(val_y, melb_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">>Output: 191669.7536453626"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veja como já melhoramos bastante. Nem ajustamos nenhum parametro, usamos os padrões, e ainda assim o modelo já retornou um resultado melhor que o da árvore de decisão, que era de 250.000."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intermediate Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Values\n",
    "\n",
    "Este capítulo dá instruções sobre como lidar com missing values. Estes valores faltantes não podem ser ignorados. Ou pelo menos vc precisa estar ciente do porquê estes valores estão faltando. A forma que vc lida com eles pode afetar significativamente o desempenho do modelo.\n",
    "\n",
    "Existem basicamente 3 approaches:\n",
    "\n",
    "- 1. Dropar as colunas com missing values\n",
    "    - Opção mais perigosa, tem que saber o que está fazendo..pois corremos o risco de perder features importantes. Imagine perder toda uma coluna com milhares de linhas por causa de uns poucos missing values! Não é a melhor das opções.\n",
    "    \n",
    "- 2. Imputação\n",
    "    - Preencher os missing values com valores. Estes valores podem ser a média da sequencia, a moda...nem sempre vão refletir a realidade, mas influenciam positivamente na precisão dos modelos preditivos e trazem melhores resultados que a opção anterior.\n",
    "- 3. Extensão da imputação\n",
    "    - Faz o mesmo processo de imputação dito anteriormente. Mas neste caso inclui mais uma coluna na tabela, indicando a origem do valor da coluna de referência. Por exemplo, imputaríamos a coluna 'salario' com a média. Teria uma coluna adicional 'salario_missing' que indicaria com ```True``` ou ```False``` se o valor da coluna 'salario' foi imputado ou não.\n",
    "\n",
    "O autor faz uma comparação do desempenho das 3 abordagens, e o melhor resultado foi a da imputação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
